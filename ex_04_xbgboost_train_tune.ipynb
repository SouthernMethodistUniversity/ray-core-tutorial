{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f8ad5d-4621-4fa2-887b-9696008d9b42",
   "metadata": {},
   "source": [
    "This demo introduces **Ray tune's** key concepts using a trivial examples. This example is derived from [Ray Tune basic example](https://docs.ray.io/en/latest/tune/examples/tune_basic_example.html). Basically, there are three basic steps or Ray Tune pattern for you as a newcomer to get started with using Ray Tune.\n",
    "\n",
    " 1. Setup your config space and define your trainable and objective function\n",
    " 2. Use tune to execute your training, supplying the appropriate arguments including: search space, [search algorithms](https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#blendsearch) or [trial schedulers](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-schedulers)\n",
    " 3. Examine analyse the results\n",
    " \n",
    " <img src=\"https://docs.ray.io/en/latest/_images/tune-workflow.png\" height=\"50%\" width=\"60%\">\n",
    "\n",
    "\n",
    "See also the [Hyperparameter Tuning References](References-Hyperparameter-Tuning.ipynb) notebook and the [Tune documentation](http://tune.io), in particular, the [API reference](https://docs.ray.io/en/latest/tune/api_docs/overview.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b8885d-b698-419f-b43f-d91a073052c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7515b4-c4eb-4068-a908-f53769ef35ab",
   "metadata": {},
   "source": [
    "## Step 1: Define our 'Trainable' training function to use with Ray Tune `ray.tune(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b632024-1e88-4972-8687-46d58a5910f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ACTORS = 4           # degree of parallel trials; each actor will have a separate trial\n",
    "NUM_OF_CPUS_PER_ACTOR = 1   # number of CPUs per actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa72d37-e6d3-4cae-ba41-4556d6dc15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_params = RayParams(num_actors=NUM_OF_ACTORS, cpus_per_actor=NUM_OF_CPUS_PER_ACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ab5961-daac-4986-a9d3-5c224990c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func_model(config:dict):\n",
    "    # create the dataset\n",
    "    train_X, train_y = load_breast_cancer(return_X_y=True)\n",
    "    # Convert to RayDMatrix data structure\n",
    "    train_set = RayDMatrix(train_X, train_y)\n",
    "\n",
    "    # Empty dictionary for the evaluation results reported back\n",
    "    # to tune\n",
    "    evals_result = {}\n",
    "\n",
    "    # Train the model with XGBoost train\n",
    "    bst = train(\n",
    "        params=config,                       # our hyperparameter search space\n",
    "        dtrain=train_set,                    # our RayDMatrix data structure\n",
    "        evals_result=evals_result,           # place holder for results\n",
    "        evals=[(train_set, \"train\")],\n",
    "        verbose_eval=False,\n",
    "        ray_params=ray_params)                # distributed parameters configs for Ray Tune\n",
    "\n",
    "    bst.save_model(\"model.xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f68cc5-6999-4bef-99e8-f68c6a5052c5",
   "metadata": {},
   "source": [
    "## Step 2: Define our hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a35e0c3-f0e5-4efd-a7a8-ffdf28dc5216",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Specify the hyperparameter search space\n",
    "config = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    \"eta\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"subsample\": tune.uniform(0.5, 1.0),\n",
    "    \"max_depth\": tune.randint(1, 9)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee450f-0eee-4fa1-ad81-f39a3247ef12",
   "metadata": {},
   "source": [
    "## Step 3: Run Ray tune main trainer and examine the results\n",
    "\n",
    "Ray Tune will launch distributed HPO, using four remote actors, each with its own instance of the trainable func\n",
    "\n",
    "<img src=\"images/ray_tune_dist_hpo.png\" height=\"50%\" width=\"60%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36a1548-90e7-4699-98d1-7e88cbab154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:58:20,958\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2022-01-04 16:58:22,278\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-04 16:58:24 (running for 00:00:01.52)<br>Memory usage on this node: 16.8/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5.0/12 CPUs, 0/0 GPUs, 0.0/10.43 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: /Users/jules/ray_results/train_func_model_2022-01-04_16-58-22<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_model_946ba_00000</td><td>RUNNING </td><td>127.0.0.1:96814</td><td style=\"text-align: right;\">0.000321294</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.586609</td></tr>\n",
       "<tr><td>train_func_model_946ba_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00597151 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.939981</td></tr>\n",
       "<tr><td>train_func_model_946ba_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.000160446</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.580016</td></tr>\n",
       "<tr><td>train_func_model_946ba_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00078595 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.577505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96814)\u001b[0m 2022-01-04 16:58:24,456\tINFO main.py:976 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96814)\u001b[0m 2022-01-04 16:58:25,897\tINFO main.py:1021 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96805)\u001b[0m [16:58:25] task [xgboost.ray]:140659783761488 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96809)\u001b[0m [16:58:25] task [xgboost.ray]:140472284872272 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96802)\u001b[0m [16:58:25] task [xgboost.ray]:140407050698320 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96810)\u001b[0m [16:58:25] task [xgboost.ray]:140423158464080 got new rank 2\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96813)\u001b[0m 2022-01-04 16:58:26,029\tINFO main.py:976 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_func_model_946ba_00000:\n",
      "  date: 2022-01-04_16-58-27\n",
      "  done: false\n",
      "  experiment_id: a85df0dd23de453facee9589f058cf26\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96814\n",
      "  time_since_restore: 2.904254913330078\n",
      "  time_this_iter_s: 2.904254913330078\n",
      "  time_total_s: 2.904254913330078\n",
      "  timestamp: 1641344307\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.080844\n",
      "  train-logloss: 0.692922\n",
      "  training_iteration: 1\n",
      "  trial_id: 946ba_00000\n",
      "  \n",
      "Result for train_func_model_946ba_00000:\n",
      "  date: 2022-01-04_16-58-27\n",
      "  done: true\n",
      "  experiment_id: a85df0dd23de453facee9589f058cf26\n",
      "  experiment_tag: 0_eta=0.00032129,max_depth=1,subsample=0.58661\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96814\n",
      "  time_since_restore: 2.9658071994781494\n",
      "  time_this_iter_s: 0.005114078521728516\n",
      "  time_total_s: 2.9658071994781494\n",
      "  timestamp: 1641344307\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.070299\n",
      "  train-logloss: 0.690905\n",
      "  training_iteration: 10\n",
      "  trial_id: 946ba_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96814)\u001b[0m 2022-01-04 16:58:27,378\tINFO main.py:1500 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 2.96 seconds (1.48 pure XGBoost training time).\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96813)\u001b[0m 2022-01-04 16:58:28,093\tINFO main.py:1021 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96806)\u001b[0m [16:58:28] task [xgboost.ray]:140620456885888 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96808)\u001b[0m [16:58:28] task [xgboost.ray]:140577641102976 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96855)\u001b[0m [16:58:28] task [xgboost.ray]:140182641278544 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96854)\u001b[0m [16:58:28] task [xgboost.ray]:140531336576592 got new rank 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-04 16:58:29 (running for 00:00:06.53)<br>Memory usage on this node: 16.7/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10.0/12 CPUs, 0/0 GPUs, 0.0/10.43 GiB heap, 0.0/5.22 GiB objects<br>Current best trial: 946ba_00000 with train-error=0.070299 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0003212936480284373, 'subsample': 0.58660883487342, 'max_depth': 1, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /Users/jules/ray_results/train_func_model_2022-01-04_16-58-22<br>Number of trials: 4/4 (1 PENDING, 2 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_model_946ba_00001</td><td>RUNNING   </td><td>127.0.0.1:96813</td><td style=\"text-align: right;\">0.00597151 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.939981</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_func_model_946ba_00002</td><td>RUNNING   </td><td>127.0.0.1:96858</td><td style=\"text-align: right;\">0.000160446</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.580016</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_func_model_946ba_00003</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">0.00078595 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.577505</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_func_model_946ba_00000</td><td>TERMINATED</td><td>127.0.0.1:96814</td><td style=\"text-align: right;\">0.000321294</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.586609</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.96581</td><td style=\"text-align: right;\">       0.690905</td><td style=\"text-align: right;\">     0.070299</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_func_model_946ba_00001:\n",
      "  date: 2022-01-04_16-58-29\n",
      "  done: false\n",
      "  experiment_id: f927df1b0ee64c198586fc72f7deba68\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96813\n",
      "  time_since_restore: 3.208714008331299\n",
      "  time_this_iter_s: 3.208714008331299\n",
      "  time_total_s: 3.208714008331299\n",
      "  timestamp: 1641344309\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.061511\n",
      "  train-logloss: 0.688244\n",
      "  training_iteration: 1\n",
      "  trial_id: 946ba_00001\n",
      "  \n",
      "Result for train_func_model_946ba_00001:\n",
      "  date: 2022-01-04_16-58-29\n",
      "  done: true\n",
      "  experiment_id: f927df1b0ee64c198586fc72f7deba68\n",
      "  experiment_tag: 1_eta=0.0059715,max_depth=2,subsample=0.93998\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96813\n",
      "  time_since_restore: 3.5143327713012695\n",
      "  time_this_iter_s: 0.007069826126098633\n",
      "  time_total_s: 3.5143327713012695\n",
      "  timestamp: 1641344309\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.042179\n",
      "  train-logloss: 0.646846\n",
      "  training_iteration: 10\n",
      "  trial_id: 946ba_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96813)\u001b[0m 2022-01-04 16:58:29,497\tINFO main.py:1500 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.51 seconds (1.40 pure XGBoost training time).\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96858)\u001b[0m 2022-01-04 16:58:29,467\tINFO main.py:976 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96858)\u001b[0m 2022-01-04 16:58:31,752\tINFO main.py:1021 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96865)\u001b[0m [16:58:31] task [xgboost.ray]:140589989887568 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96864)\u001b[0m [16:58:31] task [xgboost.ray]:140487318404688 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96867)\u001b[0m [16:58:31] task [xgboost.ray]:140307864223312 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96866)\u001b[0m [16:58:31] task [xgboost.ray]:140573216767568 got new rank 2\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96868)\u001b[0m 2022-01-04 16:58:31,991\tINFO main.py:976 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_func_model_946ba_00002:\n",
      "  date: 2022-01-04_16-58-33\n",
      "  done: false\n",
      "  experiment_id: cab894eb3b6e449b85a7ba6765df5ac4\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96858\n",
      "  time_since_restore: 3.868624210357666\n",
      "  time_this_iter_s: 3.868624210357666\n",
      "  time_total_s: 3.868624210357666\n",
      "  timestamp: 1641344313\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.049209\n",
      "  train-logloss: 0.69301\n",
      "  training_iteration: 1\n",
      "  trial_id: 946ba_00002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-04 16:58:33 (running for 00:00:10.42)<br>Memory usage on this node: 17.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10.0/12 CPUs, 0/0 GPUs, 0.0/10.43 GiB heap, 0.0/5.22 GiB objects<br>Current best trial: 946ba_00001 with train-error=0.042179 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.005971508336432206, 'subsample': 0.9399808811620621, 'max_depth': 2, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /Users/jules/ray_results/train_func_model_2022-01-04_16-58-22<br>Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_model_946ba_00002</td><td>RUNNING   </td><td>127.0.0.1:96858</td><td style=\"text-align: right;\">0.000160446</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.580016</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.86862</td><td style=\"text-align: right;\">       0.69301 </td><td style=\"text-align: right;\">     0.049209</td></tr>\n",
       "<tr><td>train_func_model_946ba_00003</td><td>RUNNING   </td><td>127.0.0.1:96868</td><td style=\"text-align: right;\">0.00078595 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.577505</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_func_model_946ba_00000</td><td>TERMINATED</td><td>127.0.0.1:96814</td><td style=\"text-align: right;\">0.000321294</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.586609</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.96581</td><td style=\"text-align: right;\">       0.690905</td><td style=\"text-align: right;\">     0.070299</td></tr>\n",
       "<tr><td>train_func_model_946ba_00001</td><td>TERMINATED</td><td>127.0.0.1:96813</td><td style=\"text-align: right;\">0.00597151 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.939981</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.51433</td><td style=\"text-align: right;\">       0.646846</td><td style=\"text-align: right;\">     0.042179</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_func_model_946ba_00002:\n",
      "  date: 2022-01-04_16-58-33\n",
      "  done: true\n",
      "  experiment_id: cab894eb3b6e449b85a7ba6765df5ac4\n",
      "  experiment_tag: 2_eta=0.00016045,max_depth=5,subsample=0.58002\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96858\n",
      "  time_since_restore: 3.9400219917297363\n",
      "  time_this_iter_s: 0.0054547786712646484\n",
      "  time_total_s: 3.9400219917297363\n",
      "  timestamp: 1641344313\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.024605\n",
      "  train-logloss: 0.691782\n",
      "  training_iteration: 10\n",
      "  trial_id: 946ba_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96858)\u001b[0m 2022-01-04 16:58:33,364\tINFO main.py:1500 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.94 seconds (1.61 pure XGBoost training time).\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96868)\u001b[0m 2022-01-04 16:58:34,296\tINFO main.py:1021 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96879)\u001b[0m [16:58:34] task [xgboost.ray]:140631329472080 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96882)\u001b[0m [16:58:34] task [xgboost.ray]:140532279606864 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96880)\u001b[0m [16:58:34] task [xgboost.ray]:140490401054288 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=96881)\u001b[0m [16:58:34] task [xgboost.ray]:140355780349520 got new rank 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_func_model_946ba_00003:\n",
      "  date: 2022-01-04_16-58-35\n",
      "  done: false\n",
      "  experiment_id: c55cee2883014e62ae17edd794dd7d63\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96868\n",
      "  time_since_restore: 3.5583560466766357\n",
      "  time_this_iter_s: 3.5583560466766357\n",
      "  time_total_s: 3.5583560466766357\n",
      "  timestamp: 1641344315\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.050967\n",
      "  train-logloss: 0.692478\n",
      "  training_iteration: 1\n",
      "  trial_id: 946ba_00003\n",
      "  \n",
      "Result for train_func_model_946ba_00003:\n",
      "  date: 2022-01-04_16-58-35\n",
      "  done: true\n",
      "  experiment_id: c55cee2883014e62ae17edd794dd7d63\n",
      "  experiment_tag: 3_eta=0.00078595,max_depth=3,subsample=0.57751\n",
      "  hostname: Juless-MacBook-Pro-16-inch-2019\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 96868\n",
      "  time_since_restore: 3.6066372394561768\n",
      "  time_this_iter_s: 0.004676103591918945\n",
      "  time_total_s: 3.6066372394561768\n",
      "  timestamp: 1641344315\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.031634\n",
      "  train-logloss: 0.686583\n",
      "  training_iteration: 10\n",
      "  trial_id: 946ba_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=96868)\u001b[0m 2022-01-04 16:58:35,555\tINFO main.py:1500 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.60 seconds (1.25 pure XGBoost training time).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-04 16:58:35 (running for 00:00:12.69)<br>Memory usage on this node: 16.5/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/10.43 GiB heap, 0.0/5.22 GiB objects<br>Current best trial: 946ba_00002 with train-error=0.024605 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.00016044584783139323, 'subsample': 0.5800161276771466, 'max_depth': 5, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /Users/jules/ray_results/train_func_model_2022-01-04_16-58-22<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_model_946ba_00000</td><td>TERMINATED</td><td>127.0.0.1:96814</td><td style=\"text-align: right;\">0.000321294</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.586609</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.96581</td><td style=\"text-align: right;\">       0.690905</td><td style=\"text-align: right;\">     0.070299</td></tr>\n",
       "<tr><td>train_func_model_946ba_00001</td><td>TERMINATED</td><td>127.0.0.1:96813</td><td style=\"text-align: right;\">0.00597151 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.939981</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.51433</td><td style=\"text-align: right;\">       0.646846</td><td style=\"text-align: right;\">     0.042179</td></tr>\n",
       "<tr><td>train_func_model_946ba_00002</td><td>TERMINATED</td><td>127.0.0.1:96858</td><td style=\"text-align: right;\">0.000160446</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.580016</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.94002</td><td style=\"text-align: right;\">       0.691782</td><td style=\"text-align: right;\">     0.024605</td></tr>\n",
       "<tr><td>train_func_model_946ba_00003</td><td>TERMINATED</td><td>127.0.0.1:96868</td><td style=\"text-align: right;\">0.00078595 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.577505</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.60664</td><td style=\"text-align: right;\">       0.686583</td><td style=\"text-align: right;\">     0.031634</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:58:35,691\tINFO tune.py:626 -- Total run time: 13.41 seconds (12.68 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Run tune\n",
    "analysis = tune.run(\n",
    "    train_func_model,\n",
    "    config=config,\n",
    "    metric=\"train-error\",\n",
    "    mode=\"min\",\n",
    "    num_samples=4,\n",
    "    resources_per_trial=ray_params.get_tune_resources()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ab3eaa-9002-4950-a29e-9790298de949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.00016044584783139323, 'subsample': 0.5800161276771466, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters\", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405aff3f-88c9-4c07-b9b1-89dfa6f7a580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py:262: UserWarning: Dataframes will use '/' instead of '.' to delimit nested result keys in future versions of Ray. For forward compatibility, set the environment variable TUNE_RESULT_DELIM='/'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>train-error</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>experiment_tag</th>\n",
       "      <th>config.tree_method</th>\n",
       "      <th>config.objective</th>\n",
       "      <th>config.eval_metric</th>\n",
       "      <th>config.eta</th>\n",
       "      <th>config.subsample</th>\n",
       "      <th>config.max_depth</th>\n",
       "      <th>config.nthread</th>\n",
       "      <th>config.n_jobs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946ba_00000</th>\n",
       "      <td>0.690905</td>\n",
       "      <td>0.070299</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>a85df0dd23de453facee9589f058cf26</td>\n",
       "      <td>2022-01-04_16-58-27</td>\n",
       "      <td>1641344307</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0_eta=0.00032129,max_depth=1,subsample=0.58661</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.586609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946ba_00001</th>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.042179</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>f927df1b0ee64c198586fc72f7deba68</td>\n",
       "      <td>2022-01-04_16-58-29</td>\n",
       "      <td>1641344309</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1_eta=0.0059715,max_depth=2,subsample=0.93998</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.939981</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946ba_00002</th>\n",
       "      <td>0.691782</td>\n",
       "      <td>0.024605</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>cab894eb3b6e449b85a7ba6765df5ac4</td>\n",
       "      <td>2022-01-04_16-58-33</td>\n",
       "      <td>1641344313</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2_eta=0.00016045,max_depth=5,subsample=0.58002</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.580016</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946ba_00003</th>\n",
       "      <td>0.686583</td>\n",
       "      <td>0.031634</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>c55cee2883014e62ae17edd794dd7d63</td>\n",
       "      <td>2022-01-04_16-58-35</td>\n",
       "      <td>1641344315</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3_eta=0.00078595,max_depth=3,subsample=0.57751</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.577505</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             train-logloss  train-error  time_this_iter_s  done  \\\n",
       "trial_id                                                          \n",
       "946ba_00000       0.690905     0.070299          0.005114  True   \n",
       "946ba_00001       0.646846     0.042179          0.007070  True   \n",
       "946ba_00002       0.691782     0.024605          0.005455  True   \n",
       "946ba_00003       0.686583     0.031634          0.004676  True   \n",
       "\n",
       "            timesteps_total episodes_total  training_iteration  \\\n",
       "trial_id                                                         \n",
       "946ba_00000            None           None                  10   \n",
       "946ba_00001            None           None                  10   \n",
       "946ba_00002            None           None                  10   \n",
       "946ba_00003            None           None                  10   \n",
       "\n",
       "                                experiment_id                 date  \\\n",
       "trial_id                                                             \n",
       "946ba_00000  a85df0dd23de453facee9589f058cf26  2022-01-04_16-58-27   \n",
       "946ba_00001  f927df1b0ee64c198586fc72f7deba68  2022-01-04_16-58-29   \n",
       "946ba_00002  cab894eb3b6e449b85a7ba6765df5ac4  2022-01-04_16-58-33   \n",
       "946ba_00003  c55cee2883014e62ae17edd794dd7d63  2022-01-04_16-58-35   \n",
       "\n",
       "              timestamp  ...  iterations_since_restore  \\\n",
       "trial_id                 ...                             \n",
       "946ba_00000  1641344307  ...                        10   \n",
       "946ba_00001  1641344309  ...                        10   \n",
       "946ba_00002  1641344313  ...                        10   \n",
       "946ba_00003  1641344315  ...                        10   \n",
       "\n",
       "                                             experiment_tag  \\\n",
       "trial_id                                                      \n",
       "946ba_00000  0_eta=0.00032129,max_depth=1,subsample=0.58661   \n",
       "946ba_00001   1_eta=0.0059715,max_depth=2,subsample=0.93998   \n",
       "946ba_00002  2_eta=0.00016045,max_depth=5,subsample=0.58002   \n",
       "946ba_00003  3_eta=0.00078595,max_depth=3,subsample=0.57751   \n",
       "\n",
       "            config.tree_method config.objective  config.eval_metric  \\\n",
       "trial_id                                                              \n",
       "946ba_00000             approx  binary:logistic    [logloss, error]   \n",
       "946ba_00001             approx  binary:logistic    [logloss, error]   \n",
       "946ba_00002             approx  binary:logistic    [logloss, error]   \n",
       "946ba_00003             approx  binary:logistic    [logloss, error]   \n",
       "\n",
       "             config.eta  config.subsample config.max_depth config.nthread  \\\n",
       "trial_id                                                                    \n",
       "946ba_00000    0.000321          0.586609                1              1   \n",
       "946ba_00001    0.005972          0.939981                2              1   \n",
       "946ba_00002    0.000160          0.580016                5              1   \n",
       "946ba_00003    0.000786          0.577505                3              1   \n",
       "\n",
       "            config.n_jobs  \n",
       "trial_id                   \n",
       "946ba_00000             1  \n",
       "946ba_00001             1  \n",
       "946ba_00002             1  \n",
       "946ba_00003             1  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.results_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7f8e5-bf4c-436f-95b1-8609aecf170f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1886c8e-70ba-4776-94cd-a12916732f67",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    " * [Ray Train: Tune: Scalable Hyperparameter Tuning](https://docs.ray.io/en/master/tune/index.html)\n",
    " * [Introducing Distributed XGBoost Training with Ray](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray)\n",
    " * [How to Speed Up XGBoost Model Training](https://www.anyscale.com/blog/how-to-speed-up-xgboost-model-training)\n",
    " * [XGBoost-Ray Project](https://github.com/ray-project/xgboost_ray)\n",
    " * [Distributed XGBoost on Ray](Distributed XGBoost on Ray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
